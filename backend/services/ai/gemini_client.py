import os
import json
import re
import asyncio
from typing import Dict, List, Any, Optional
from google import genai
from pydantic import BaseModel

class GeminiClient:
    """
    Backend client for Google Gemini API.
    Handles central AI logic for THEKEY.
    """
    # Available models for this API key (verified via list_models)
    # Note: gemini-1.5-flash is NOT available for this API key
    # Using 2.0-flash-lite for best free tier performance
    MODELS = [
        'models/gemini-2.0-flash',       # Primary: Fast, latest 2.0 version
        'models/gemini-2.0-flash-lite',  # Lite: Efficient
        'models/gemini-1.5-flash',       # Stable Fallback
        'models/gemini-1.5-pro',         # High Capability Fallback
    ]

    # =========================================
    # AI SAFETY RAILS - MANDATORY FOR ALL PROMPTS
    # =========================================
    SAFETY_RAILS = """
=== CRITICAL AI SAFETY RESTRICTIONS ===
You are THEKEY Trading Survival Coach. You MUST follow these rules:

‚ùå NEVER DO:
1. Predict price direction (up/down/sideways/moon/crash)
2. Suggest specific entry or exit price points
3. Recommend BUY or SELL decisions
4. Provide market forecasts or timing advice
5. Mention specific price targets or levels
6. Give opinions on whether a trade will be profitable

‚úÖ ALWAYS DO:
1. Focus on trading PSYCHOLOGY and DISCIPLINE
2. Analyze the trader's PROCESS, not the outcome
3. Discuss risk management PRINCIPLES
4. Provide emotional support and self-awareness
5. Encourage journaling and reflection

If asked for trading signals, ALWAYS respond:
"T√¥i l√† Coach v·ªÅ k·ª∑ lu·∫≠t v√† t√¢m l√Ω, kh√¥ng ph·∫£i c·ªë v·∫•n v·ªÅ ƒëi·ªÉm v√†o l·ªánh. 
H√£y t·∫≠p trung v√†o quy tr√¨nh c·ªßa b·∫°n thay v√¨ d·ª± ƒëo√°n gi√°."

=== END SAFETY RESTRICTIONS ===

"""

    
    def __init__(self):
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable not set")
        self.client = genai.Client(api_key=api_key)
        # Simple memory cache for repeated expensive calls
        self._market_cache = None
        self._market_cache_time = 0
        self._checkin_cache = {} # Keyed by user context
        self._checkin_cache_time = 0
        self._lock = asyncio.Lock()
        self._semaphore = asyncio.Semaphore(2) # Allow max 2 concurrent AI calls
    
    async def _generate(self, prompt: str) -> str:
        """Helper to generate content with multiple model fallback and concurrency control."""
        async with self._semaphore:
            max_retries_per_model = 2
            last_exception = None
            
            # Prepend safety rails to every prompt
            safe_prompt = self.SAFETY_RAILS + prompt
            
            for model_id in self.MODELS:
                delay = 1
                for i in range(max_retries_per_model):
                    try:
                        response = await self.client.aio.models.generate_content(
                            model=model_id,
                            contents=safe_prompt
                        )
                        if not response or not response.text:
                            raise ValueError(f"Empty response from Gemini {model_id}")
                        return response.text
                    except Exception as e:
                        last_exception = e
                        error_msg = str(e).lower()
                        
                        # If its a quota error (429) or not found (404), maybe try next model
                        if "429" in error_msg:
                            if "limit: 0" in error_msg:
                                print(f"‚ö†Ô∏è Model {model_id} has 0 limit. Trying next model...")
                                break # Move to next model
                            
                            print(f"‚ÑπÔ∏è Quota hit for {model_id}. Retry {i+1}/{max_retries_per_model}...")
                            await asyncio.sleep(delay)
                            delay *= 2
                        elif "404" in error_msg or "not found" in error_msg:
                            print(f"‚ö†Ô∏è Model {model_id} not found. Trying next model...")
                            break # Move to next model
                        else:
                            print(f"‚ùå Gemini Error ({model_id}): {e}")
                            # For other errors, wait a bit then try one more retry or next model
                            await asyncio.sleep(0.5)
            
            if last_exception:
                raise last_exception
            return ""

    def _clean_and_parse_json(self, text: str) -> Dict:
        """Parse JSON from Gemini response, cleaning markdown if present."""
        if not text or not text.strip():
            raise ValueError("Empty response received from Gemini")
            
        # Clean markdown formatting
        text = re.sub(r'```json\n?', '', text)
        text = re.sub(r'```\n?', '', text)
        text = text.strip()
        
        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            # Attempt to extract JSON if it's embedded in other text
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group())
                except:
                    pass
            raise ValueError(f"Failed to parse JSON response: {text[:100]}...") from e

    async def generate_checkin_questions(self, context: Dict) -> List[Dict]:
        """Generate personalized check-in questions with caching."""
        import time
        now = time.time()
        
        # Cache key based on recent trades count
        cache_key = f"q_{context.get('recent_trades_count', 0)}"
        if cache_key in self._checkin_cache and (now - self._checkin_cache_time < 3600):
            return self._checkin_cache[cache_key]
    async def generate_json_response(self, prompt: str, system_prompt: str) -> Dict[str, Any]:
        """Generic helper to get JSON from Gemini."""
        full_prompt = f"{system_prompt}\n\nInput Context:\n{prompt}\n\nReturn ONLY valid JSON."
        try:
            response_text = await self._generate(full_prompt)
            return self._clean_and_parse_json(response_text)
        except Exception as e:
            print(f"‚ùå Gemini JSON Error: {e}")
            raise e

    async def analyze_checkin(self, answers: List[Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Ph√¢n t√≠ch check-in v√† t·∫°o 'Daily Growth Insight' v·ªõi phong c√°ch Kaito."""
        system_prompt = """B·∫°n l√† Kaito. Ph√¢n t√≠ch c√¢u tr·∫£ l·ªùi check-in v√† t·∫°o "Daily Growth Insight":
        
        Tr·∫£ v·ªÅ JSON:
        {
          "emotional_state": "FOCUSED" | "ANXIOUS" | "CALM" | "TILTED" | "CONFIDENT",
          "state_intensity": 1-5,
          "insights": [
            {
              "type": "PATTERN_RECOGNITION" | "OPPORTUNITY" | "WARNING",
              "title": "Ti√™u ƒë·ªÅ",
              "description": "M√¥ t·∫£ chi ti·∫øt",
              "evidence": "D·∫´n ch·ª©ng t·ª´ l·ªãch s·ª≠ h√†nh vi"
            }
          ],
          "daily_prescription": {
            "mindset_shift": "1 t∆∞ duy c·∫ßn t·∫≠p trung h√¥m nay",
            "behavioral_rule": "1 quy t·∫Øc h√†nh vi c·ª• th·ªÉ",
            "success_metric": "C√°ch ƒëo l∆∞·ªùng th√†nh c√¥ng h√¥m nay"
          },
          "encouragement": "1 c√¢u ƒë·ªông vi√™n c√° nh√¢n ho√°",
          "progress_marker": {
            "milestone": "M·ªëc ti·∫øn b·ªô h√¥m nay (n·∫øu c√≥)",
            "visual_metaphor": "·∫®n d·ª• tr·ª±c quan, v√≠ d·ª•: 'C√¢y k·ª∑ lu·∫≠t ra l√° m·ªõi'"
          }
        }
        
        NGUY√äN T·∫ÆC: Lu√¥n t√¨m ki·∫øm TI·∫æN B·ªò, d√πng ng√¥n ng·ªØ t√≠ch c·ª±c, h∆∞·ªõng v·ªÅ t∆∞∆°ng lai."""
        
        try:
            return await self.generate_json_response(json.dumps({"answers": answers, "context": context}, ensure_ascii=False), system_prompt)
        except Exception:
            return {
                "emotional_state": "CALM",
                "state_intensity": 1,
                "insights": [{"type": "OPPORTUNITY", "title": "S·ª± kh·ªüi ƒë·∫ßu k·ª∑ lu·∫≠t", "description": "B·∫°n ƒëang b·∫Øt ƒë·∫ßu ng√†y m·ªõi v·ªõi s·ª± hi·ªán di·ªán tuy·ªát v·ªùi.", "evidence": "Ho√†n th√†nh check-in"}],
                "daily_prescription": {"mindset_shift": "H√£y ki√™n nh·∫´n", "behavioral_rule": "Ch·ªâ giao d·ªãch khi c√≥ setup", "success_metric": "S·ª± b√¨nh an khi ƒë√≥ng m√°y"},
                "encouragement": "Ch√∫c b·∫°n m·ªôt ng√†y giao d·ªãch t·ªânh t√°o!",
                "progress_marker": {"milestone": "Duy tr√¨ k·ª∑ lu·∫≠t", "visual_metaphor": "H·∫°t m·∫ßm k·ª∑ lu·∫≠t ƒëang n·∫£y m·∫ßm"}
            }
    async def generate_checkin_questions(self, context: Dict) -> List[Dict]:
        """Generate personalized check-in questions with 'Mind Scan' themes."""
        import time
        now = time.time()
        
        # Cache key based on recent trades count
        cache_key = f"q_{context.get('recent_trades_count', 0)}"
        if cache_key in self._checkin_cache and (now - self._checkin_cache_time < 3600):
            return self._checkin_cache[cache_key]

        system_prompt = """
        B·∫°n l√† Kaito - Hu·∫•n luy·ªán vi√™n k·ª∑ lu·∫≠t trading. 
        Sinh 3 c√¢u h·ªèi tr·∫Øc nghi·ªám cho check-in s√°ng nay (Mind Scan), TU√ÇN TH·ª¶:
        1. C√ÇU H·ªéI 1: ƒê√°nh gi√° nƒÉng l∆∞·ª£ng & t√¢m tr·∫°ng (ENERGY)
        2. C√ÇU H·ªéI 2: Nh·∫≠n th·ª©c v·ªÅ r·ªßi ro & th·ªã tr∆∞·ªùng (RISK_AWARENESS)
        3. C√ÇU H·ªéI 3: M·ª•c ti√™u & k·∫ø ho·∫°ch h√†nh vi h√¥m nay (BEHAVIORAL_INTENT)
        
        Xoay v√≤ng qua c√°c ch·ªß ƒë·ªÅ, kh√¥ng l·∫∑p l·∫°i t·∫ª nh·∫°t. 
        S·ª≠ d·ª•ng ti·∫øng Vi·ªát th√¢n thi·ªán, ƒë√¥i khi d√πng emoji.
        
        Format JSON:
        {
          "questions": [
            {
              "id": 1,
              "text": "...",
              "options": [
                {"value": 0, "text": "Option A"},
                {"value": 1, "text": "Option B"},
                {"value": 2, "text": "Option C"}
              ],
              "theme": "ENERGY" | "RISK_AWARENESS" | "BEHAVIORAL_INTENT"
            }
          ],
          "daily_theme": "Nh·∫≠n di·ªán c·∫£m x√∫c"
        }
        """
        
        prompt = f"Context: {json.dumps(context, ensure_ascii=False)}"
        
        try:
            result = await self.generate_json_response(prompt, system_prompt)
            questions = result.get("questions", [])
            for q in questions:
                # Ensure structure for frontend
                q['type'] = 'multiple-choice'
                q['multiple_choice'] = {"options": [opt['text'] for opt in q.get('options', [])]}
            
            if questions:
                self._checkin_cache = {cache_key: questions}
                self._checkin_cache_time = now
            return questions
        except Exception as e:
            print(f"‚ùå Gemini Error (generate_checkin_questions): {e}")
            return [
                {"id": 1, "text": "NƒÉng l∆∞·ª£ng s√°ng nay c·ªßa b·∫°n th·∫ø n√†o?", "type": "multiple-choice", "multiple_choice": {"options": ["R·∫•t t·ªët", "H∆°i m·ªát", "ƒêang ·ª©c ch·∫ø"]}},
                {"id": 2, "text": "B·∫°n c√≥ th·∫•y th·ªã tr∆∞·ªùng ƒëang d·ª• d·ªó m√¨nh kh√¥ng?", "type": "multiple-choice", "multiple_choice": {"options": ["Kh√¥ng, t√¥i c√≥ k·∫ø ho·∫°ch", "H∆°i FOMO", "ƒêang r·∫•t mu·ªën v√†o l·ªánh"]}},
                {"id": 3, "text": "M·ª•c ti√™u quan tr·ªçng nh·∫•t h√¥m nay?", "type": "multiple-choice", "multiple_choice": {"options": ["Tu√¢n th·ªß stoploss", "Ch·ªâ v√†o ƒë√∫ng setup", "D·ª´ng s·ªõm n·∫øu l·ªó"]}}
            ]

    async def get_trade_evaluation(self, context: Dict) -> Dict:
        """ƒê√°nh gi√° l·ªánh y√™u c·∫ßu nh∆∞ m·ªôt 'Nghi th·ª©c tr∆∞·ªõc giao d·ªãch' (Kaito)."""
        system_prompt = """B·∫°n l√† Kaito - Coach k·ª∑ lu·∫≠t. ƒê√°nh gi√° l·ªánh n√†y nh∆∞ m·ªôt "Nghi th·ª©c tr∆∞·ªõc giao d·ªãch".
        
        Tr·∫£ v·ªÅ JSON:
        {
          "decision": "ALLOW" | "WARN" | "BLOCK",
          "reason": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn (d∆∞·ªõi 10 t·ª´)",
          "behavioral_insight": "Ph√¢n t√≠ch t√¢m l√Ω ƒë·∫±ng sau l·ªánh n√†y",
          "alternatives": [
            {
              "type": "SCALE_IN" | "WAIT_FOR_CONFIRMATION" | "PAPER_TRADE" | "REDUCE_SIZE",
              "description": "M√¥ t·∫£ chi ti·∫øt",
              "rationale": "T·∫°i sao ph∆∞∆°ng √°n n√†y t·ªët h∆°n?"
            }
          ],
          "coaching_question": "C√¢u h·ªèi gi√∫p user t·ª± nh·∫≠n th·ª©c",
          "immediate_action": "H√†nh ƒë·ªông c·ª• th·ªÉ user n√™n l√†m NGAY",
          "tone": "SUPPORTIVE" | "CAUTIOUS" | "EMPOWERING"
        }
        
        GI·ªåNG ƒêI·ªÜU: ƒê·ªìng c·∫£m nh∆∞ng ki√™n ƒë·ªãnh. N·∫øu user ƒëang h∆∞ng ph·∫•n, h√£y nh·∫Øc v·ªÅ risk. N·∫øu tilted, h√£y ƒë·ªìng c·∫£m v√† khuy√™n d·ª´ng."""
        
        try:
            return await self.generate_json_response(json.dumps(context, ensure_ascii=False), system_prompt)
        except Exception:
            return {
                "decision": "WARN",
                "reason": "H√£y ch·∫≠m l·∫°i v√† ki·ªÉm tra quy tr√¨nh.",
                "behavioral_insight": "B·∫°n ƒëang trong tr·∫°ng th√°i c·∫ßn s·ª± t·ªânh t√°o.",
                "alternatives": [{"type": "REDUCE_SIZE", "description": "Gi·∫£m 50% kh·ªëi l∆∞·ª£ng", "rationale": "Gi·∫£m √°p l·ª±c t√¢m l√Ω"}],
                "coaching_question": "L·ªánh n√†y c√≥ th·ª±c s·ª± n·∫±m trong k·∫ø ho·∫°ch ban ƒë·∫ßu?",
                "immediate_action": "U·ªëng m·ªôt ng·ª•m n∆∞·ªõc v√† h√≠t th·ªü s√¢u 3 l·∫ßn.",
                "tone": "CAUTIOUS"
            }

    async def analyze_trade(self, trade_data: Dict, user_stats: Dict) -> Dict:
        """T·∫°o 'Behavioral Insight Card' cho l·ªánh v·ª´a ƒë√≥ng (Kaito)."""
        system_prompt = """B·∫°n l√† Kaito. T·∫°o "Behavioral Insight Card" cho l·ªánh v·ª´a ƒë√≥ng:
        
        Tr·∫£ v·ªÅ JSON:
        {
          "trade_summary": "1 c√¢u m√¥ t·∫£ ng·∫Øn",
          "behavioral_pattern": {
            "identified": true/false,
            "pattern_name": "T√™n pattern",
            "description": "M√¥ t·∫£ pattern",
            "frequency": "ƒê√£ x·∫£y ra bao nhi√™u l·∫ßn?"
          },
          "growth_observation": {
            "improvement": "ƒêi·ªÉm ti·∫øn b·ªô so v·ªõi tr∆∞·ªõc",
            "area_to_work": "ƒêi·ªÉm c·∫ßn c·∫£i thi·ªán",
            "suggestion": "ƒê·ªÅ xu·∫•t c·ª• th·ªÉ cho l·∫ßn sau"
          },
          "coaching_question": "1 c√¢u h·ªèi gi√∫p reflection s√¢u h∆°n",
          "wisdom_nugget": "1 b√†i h·ªçc ng·∫Øn t·ª´ l·ªánh n√†y"
        }
        
        NGUY√äN T·∫ÆC: Lu√¥n t√¨m ki·∫øm ƒêI·ªÇM S√ÅNG (v√≠ d·ª•: TU√ÇN TH·ª¶ STOPLOSS l√† th√†nh c√¥ng l·ªõn)."""
        
        try:
            return await self.generate_json_response(json.dumps({"trade": trade_data, "stats": user_stats}, ensure_ascii=False), system_prompt)
        except Exception:
            return {
                "trade_summary": "L·ªánh giao d·ªãch ƒë√£ ho√†n t·∫•t.",
                "behavioral_pattern": {"identified": False, "pattern_name": None, "description": None, "frequency": None},
                "growth_observation": {"improvement": "S·ª± hi·ªán di·ªán", "area_to_work": "K·ª∑ lu·∫≠t", "suggestion": "H√£y duy tr√¨ quy tr√¨nh"},
                "coaching_question": "B·∫°n h·ªçc ƒë∆∞·ª£c g√¨ t·ª´ l·ªánh n√†y?",
                "wisdom_nugget": "M·ªói l·ªánh l√† m·ªôt b√†i h·ªçc."
            }

        """ƒê√°nh gi√° quy tr√¨nh trading d∆∞·ªõi d·∫°ng 'Kata Assessment' (Kaito)."""
        system_prompt = """B·∫°n l√† Kaito. ƒê√°nh gi√° quy tr√¨nh trading d∆∞·ªõi d·∫°ng "Kata Assessment":
        
        Tr·∫£ v·ªÅ JSON:
        {
          "kata_score": 0-100,
          "strength_zones": [
            {
              "zone": "SETUP" | "EXECUTION" | "RISK_MANAGEMENT" | "PSYCHOLOGY",
              "score": 0-100,
              "feedback": "ƒê√°nh gi√° chi ti·∫øt"
            }
          ],
          "personalized_kata": {
            "name": "T√™n Kata c√° nh√¢n ho√°",
            "core_principles": ["Nguy√™n t·∫Øc 1", "Nguy√™n t·∫Øc 2"],
            "daily_practice": "B√†i t·∫≠p th·ª±c h√†nh 5 ph√∫t m·ªói ng√†y"
          },
          "transformation_story": {
            "before": "B·∫°n tu·∫ßn tr∆∞·ªõc ·ªü ƒëi·ªÉm n√†y",
            "after": "B·∫°n hi·ªán t·∫°i ƒë√£ ti·∫øn b·ªô th·∫ø n√†o",
            "next_step": "B∆∞·ªõc ti·∫øp theo ƒë·ªÉ master kata n√†y"
          }
        }
        
        TI√äU CH√ç: T·∫≠p trung v√†o TI·∫æN B·ªò, t·∫°o c·∫£m gi√°c "ƒëang tr√™n h√†nh tr√¨nh master k·ªπ nƒÉng"."""
        
        try:
            return await self.generate_json_response(json.dumps({"trades": trade_history, "checkins": checkin_history}, ensure_ascii=False), system_prompt)
        except Exception:
            return {
                "kata_score": 70,
                "strength_zones": [{"zone": "PSYCHOLOGY", "score": 75, "feedback": "Duy tr√¨ s·ª± b√¨nh tƒ©nh t·ªët"}],
                "personalized_kata": {"name": "The Calm Warrior", "core_principles": ["H√≠t th·ªü", "Ch·ªù ƒë·ª£i"], "daily_practice": "Thi·ªÅn 5 ph√∫t"},
                "transformation_story": {"before": "D·ªÖ b·ªã l√¥i cu·ªën", "after": "ƒê√£ bi·∫øt quan s√°t", "next_step": "T·ªëi ∆∞u h√≥a Entry"}
            }

    async def generate_market_analysis(self) -> Dict:
        """Analyze market danger level with real-time web search, 8s timeout, and 10-minute caching."""
        import time
        import asyncio
        import random
        now = time.time()
        
        # Random trading tips for engaging fallback
        TRADING_TIPS = [
            {"headline": "K·ª∑ lu·∫≠t l√† v≈© kh√≠ m·∫°nh nh·∫•t c·ªßa trader.", "tip": "ƒê·∫∑t stop loss tr∆∞·ªõc khi v√†o l·ªánh."},
            {"headline": "Kh√¥ng c√≥ ph√¢n t√≠ch th·ªã tr∆∞·ªùng? Kh√¥ng v√†o l·ªánh.", "tip": "Ch·ªù d·ªØ li·ªáu ·ªïn ƒë·ªãnh tr∆∞·ªõc khi giao d·ªãch."},
            {"headline": "M·ªôt ng√†y kh√¥ng trade c≈©ng l√† chi·∫øn th·∫Øng.", "tip": "ƒê·ª©ng ngo√†i khi kh√¥ng ch·∫Øc ch·∫Øn."},
            {"headline": "B·∫£o v·ªá v·ªën quan tr·ªçng h∆°n l·ª£i nhu·∫≠n.", "tip": "Gi·∫£m 50% kh·ªëi l∆∞·ª£ng khi th·ªã tr∆∞·ªùng m·ªù m·ªãt."},
            {"headline": "Trader gi·ªèi bi·∫øt khi n√†o KH√îNG v√†o l·ªánh.", "tip": "Ki√™n nh·∫´n ch·ªù c∆° h·ªôi r√µ r√†ng."},
            {"headline": "Revenge trade = T·ª± h·ªßy t√†i kho·∫£n.", "tip": "Ngh·ªâ 30 ph√∫t sau m·ªói l·ªánh thua."},
            {"headline": "Trend is your friend, cho ƒë·∫øn khi n√≥ k·∫øt th√∫c.", "tip": "Lu√¥n x√°c ƒë·ªãnh xu h∆∞·ªõng tr∆∞·ªõc khi trade."},
            {"headline": "Volume nh·ªè, r·ªßi ro nh·ªè, s·ªëng l√¢u h∆°n.", "tip": "Max 2% r·ªßi ro m·ªói l·ªánh."},
        ]
        
        def get_random_fallback():
            tip = random.choice(TRADING_TIPS)
            return {
                "danger_level": "CAUTION",
                "danger_score": 50,
                "color_code": "üü°",
                "headline": tip["headline"],
                "risk_factors": [{"factor": "Ch·ªù d·ªØ li·ªáu", "severity": "MEDIUM", "description": tip["tip"]}],
                "factors": {"volatility": 50, "liquidity": 50, "leverage": 50, "sentiment": 50, "events": 50},
                "recommendation": {
                    "action": "WAIT",
                    "position_adjustment": "Gi·∫£m 50% ho·∫∑c ƒë·ª©ng ngo√†i.",
                    "stop_adjustment": "N·ªõi r·ªông stop loss n·∫øu ƒë√£ c√≥ l·ªánh.",
                    "rationale": tip["tip"]
                }
            }
        
        # Return cache if less than 10 minutes old (600 seconds)
        if self._market_cache and (now - self._market_cache_time < 600):
            return self._market_cache

        prompt = f"""
        Analyze the CURRENT crypto market conditions (BTC, ETH, and overall sentiment).
        Directly search for 'crypto market sentiment', 'BTC price action today', and 'crypto liquidations'.
        
        Task: Decide if the current market is 'SAFE', 'CAUTION', or 'DANGER'.
        Provide exactly this JSON:
        {{
          "danger_level": "SAFE" | "CAUTION" | "DANGER",
          "danger_score": 0-100,
          "color_code": "üü¢" | "üü°" | "üî¥",
          "headline": "One short Vietnamese warning headline",
          "risk_factors": [{{"factor": "...", "severity": "HIGH/MEDIUM/LOW", "description": "..."}}],
          "factors": {{"volatility": 0-100, "liquidity": 0-100, "leverage": 0-100, "sentiment": 0-100, "events": 0-100}},
          "recommendation": {{"action": "Wait/Trade/Reduce", "position_adjustment": "...", "stop_adjustment": "...", "rationale": "..."}}
        }}

        LANGUAGE: Vietnamese. Return ONLY valid JSON.
        """
        try:
            # Use 8 second timeout to avoid UI stuck
            async with asyncio.timeout(8):
                async with self._semaphore:
                    safe_prompt = self.SAFETY_RAILS + prompt
                    response = await self.client.aio.models.generate_content(
                        model='models/gemini-2.0-flash',
                        contents=safe_prompt,
                        config={
                            'tools': [{'google_search': {}}]
                        }
                    )
                    
                    if not response or not response.text:
                        # Fallback to normal generation if search fails or model unavailable
                        response_text = await self._generate(prompt)
                    else:
                        response_text = response.text

            result = self._clean_and_parse_json(response_text)
            
            # Update cache on success
            self._market_cache = result
            self._market_cache_time = now
            return result
        except asyncio.TimeoutError:
            print("‚è±Ô∏è Market analysis timeout (8s) - returning cached or fallback")
            if self._market_cache:
                return self._market_cache
            return get_random_fallback()
        except Exception as e:
            print(f"‚ùå Gemini Error (generate_market_analysis): {e}")
            
            # If AI fails, still return previous cache if available, even if old
            if self._market_cache:
                return self._market_cache
            
            return get_random_fallback()

    async def generate_chat_response(self, message: str, history: List[Dict], mode: str = "COACH") -> Dict:
        """Generate a response for the AI Coach/Protector chat using Kaito persona."""
        system_prompt = """
        B·∫°n l√† Kaito - Hu·∫•n luy·ªán vi√™n trading chuy√™n v·ªÅ t√¢m l√Ω v√† k·ª∑ lu·∫≠t.
        
        VAI TR√í:
        1. Ng∆∞·ªùi ƒë·ªìng h√†nh th·∫•u hi·ªÉu, kh√¥ng ph√°n x√©t.
        2. Ng∆∞·ªùi ƒë·∫∑t c√¢u h·ªèi gi√∫p t·ª± nh·∫≠n th·ª©c.
        3. Ng∆∞·ªùi g·ª£i √Ω b√†i t·∫≠p th·ª±c h√†nh nh·ªè.
        
        GI·ªåNG ƒêI·ªÜU:
        - Khi user th·∫Øng: Kh√°m ph√° l√Ω do th√†nh c√¥ng ƒë·ªÉ l·∫∑p l·∫°i.
        - Khi user thua: T·∫≠p trung v√†o b√†i h·ªçc, kh√¥ng ph·∫£i P&L.
        - Khi user tilted: ƒê·ªìng c·∫£m, khuy√™n d·ª´ng l·∫°i h√≠t th·ªü.
        - Khi user h·ªèi t√≠n hi·ªáu: T·ª´ ch·ªëi kh√©o l√©o, t·∫≠p trung v√†o quy tr√¨nh.
        
        TR√ÅNH: L·ªùi khuy√™n t√†i ch√≠nh, d·ª± ƒëo√°n th·ªã tr∆∞·ªùng, ph√°n x√©t.
        """
        
        prompt = f"""
        User Message: {message}
        Chat History: {json.dumps(history[-10:])}
        
        Return JSON ONLY:
        {{
           "display_text": "Ph·∫£n h·ªìi b·∫±ng ti·∫øng Vi·ªát",
           "internal_reasoning": "English reasoning"
        }}
        """
        try:
            return await self.generate_json_response(prompt, system_prompt)
        except Exception as e:
            print(f"‚ùå Gemini Error (generate_chat_response): {e}")
            return {"display_text": "T√¥i lu√¥n ·ªü ƒë√¢y ƒë·ªÉ l·∫Øng nghe b·∫°n. H√£y c√πng h√≠t th·ªü s√¢u m·ªôt ch√∫t nh√©.", "internal_reasoning": str(e)}

    async def detect_emotional_tilt(self, stats: Dict, history: List[Dict]) -> Dict:
        """Detect if the trader is on 'tilt' and needs intervention."""
        prompt = f"""
        Analyze these trading stats and history for signs of emotional tilt (revenge trading, frustration, despair).
        Stats: {json.dumps(stats)}
        History: {json.dumps(history[-5:])}
        
        Provide:
        1. tilt_detected (boolean).
        2. severity (LOW, MEDIUM, HIGH).
        3. intervention_message (Vietnamese).
        4. suggested_action (Vietnamese).
        
        Return ONLY valid JSON.
        """
        try:
            response_text = await self._generate(prompt)
            data = self._clean_and_parse_json(response_text)
            if not data.get("tilt_detected", False):
                return {"tilt_detected": False}
            
            # Ensure it has the structure expected by CrisisInterventionModal (mostly)
            # or at least the fields used in CrisisInterventionModal
            full_data = {
                "tilt_detected": True,
                "level": f"LEVEL_{2 if data.get('severity') == 'MEDIUM' else (3 if data.get('severity') == 'HIGH' else 1)}",
                "reasons": [data.get("intervention_message", "C·∫£m x√∫c ƒëang kh√¥ng ·ªïn ƒë·ªãnh")],
                "userMetrics": {
                    "winRateAfterLoss": 20,
                    "normalWinRate": 45,
                    "revengeTradeLoss": 150,
                    "emotionalLevel": 8
                },
                "recommendedActions": [
                    {
                        "id": "1",
                        "title": "Ngh·ªâ ng∆°i",
                        "description": data.get("suggested_action", "H√£y d·ª´ng giao d·ªãch ngay."),
                        "duration": "15 minutes",
                        "icon": "üßò",
                        "actionType": "BREATHING"
                    }
                ],
                "estimatedRisk": 85,
                "cooldownMinutes": 15
            }
            return full_data
        except Exception as e:
            print(f"‚ùå Gemini Error (detect_emotional_tilt): {e}")
            return {"tilt_detected": False}

    async def generate_weekly_goals(self, history: List[Dict], stats: Dict, checkin_history: List[Dict]) -> Dict:
        """Generate 2 personalized goals for the upcoming week."""
        prompt = f"""
        Generate 2 trading discipline goals for the next week.
        Stats: {json.dumps(stats)}
        History: {json.dumps(history[-20:])}
        
        Return a JSON with 'primary_goal', 'secondary_goal' objects including title, description, metric, target.
        LANGUAGE: Vietnamese.
        """
        try:
            response_text = await self._generate(prompt)
            return self._clean_and_parse_json(response_text)
        except Exception as e:
            print(f"‚ùå Gemini Error (generate_weekly_goals): {e}")
            return {"primary_goal": {"title": "K·ª∑ lu·∫≠t th√©p", "description": "Tu√¢n th·ªß tuy·ªát ƒë·ªëi Stop Loss."}, "secondary_goal": {"title": "Nh·∫≠t k√Ω ƒë·∫ßy ƒë·ªß", "description": "Ghi ch√©p l·∫°i t·∫•t c·∫£ c√°c l·ªánh."}}

    async def generate_weekly_report(self, history: List[Dict]) -> Dict:
        """Generate a weekly summary report."""
        prompt = f"""
        Summarize the past week for this trader.
        History: {json.dumps(history)}
        
        Provide:
        1. survival_score (0-100).
        2. key_achievements (List, Vietnamese).
        3. areas_to_improve (List, Vietnamese).
        
        Return ONLY valid JSON.
        """
        try:
            response_text = await self._generate(prompt)
            return self._clean_and_parse_json(response_text)
        except Exception as e:
            print(f"‚ùå Gemini Error (generate_weekly_report): {e}")
            return {"survival_score": 85, "key_achievements": ["Duy tr√¨ k·ª∑ lu·∫≠t."], "areas_to_improve": ["Ki·ªÉm so√°t t√¢m l√Ω."]}

    async def analyze_trader_archetype(self, history: List[Dict], checkin_history: List[Dict]) -> Dict:
        """Analyze the trader's behavioral archetype."""
        prompt = f"""
        Analyze the trader's style based on data and determine their archetype.
        History: {json.dumps(history)}
        Checkins: {json.dumps(checkin_history)}
        
        Provide:
        1. archetype (STUBBORN, GAMBLER, GUARDIAN, etc.)
        2. description (Vietnamese)
        3. primary_strength (Vietnamese)
        4. primary_weakness (Vietnamese)
        
        Return ONLY valid JSON.
        """
        try:
            response_text = await self._generate(prompt)
            return self._clean_and_parse_json(response_text)
        except Exception as e:
            print(f"‚ùå Gemini Error (analyze_trader_archetype): {e}")
            return {"archetype": "GUARDIAN", "description": "Ng∆∞·ªùi b·∫£o v·ªá k·ª∑ lu·∫≠t.", "primary_strength": "Ki√™n nh·∫´n.", "primary_weakness": "C·∫©n th·∫≠n qu√° m·ª©c."}

gemini_client = GeminiClient()
